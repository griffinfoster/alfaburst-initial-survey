{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ALFABURST Event Buffer Feature Builder\n",
    "\n",
    "The ALFABURST commensal FRB search survey searches for dedisperesed pulses above a signal to noise of 10 across of 56 MHz band. Data is processed in time windows of 2^15 * 256 microseconds (~8.4 seconds), 512 frequency channels. If a pulse is detected the entire time window is recorded to disk.\n",
    "\n",
    "The vast majority of detected pulses are false-positive events due to human-made RFI. Only a small minority of events (less than 1%) is due to astrophysical sources, primarily bright pulses from pulsars. The RFI takes on a wide range of characteristics. In the processing pipeline the brightest RFI is clipped and replaced, but low-level RFI and spectra statistics still lead to an excess of false-positives.\n",
    "\n",
    "In order to automate the processing the 150000+ recorded buffers a classifier model would be useful to ***probabilistically*** classify each event. Approximately 15000 events have been labelled into 10 different categories. We can use this *labelled* data set for training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle as pickle\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#BASE_DATA_PATH = '/local/griffin/data/alfaburst/priorityModel/' #AX\n",
    "BASE_DATA_PATH = '/home/griffin/data/alfa/priorityModel/' #WATERMARK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Build buffer database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "baseBufferPklFile = BASE_DATA_PATH + 'ALFAbuffers.pkl'\n",
    "\n",
    "# load baseBufferPkl\n",
    "df = pd.read_pickle(baseBufferPklFile)\n",
    "\n",
    "# create a predicted label column with 'unlabelled' label\n",
    "df = df.assign(predictLabel=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The intial buffer dataframe contains a list of all buffers with meta-data such as time, beam ID, and buffer ID. There is also global statistics for each buffer usch as number of events in the buffer and the maximum SNR event. The label column is initially empty, we need to fill it with the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Beam        Buffer      MJDstart        bestDM       bestSNR  \\\n",
      "count  73282.000000  73282.000000  73282.000000  73282.000000  73282.000000   \n",
      "mean       3.556617    211.437952  57392.275750    994.132829     12.890546   \n",
      "std        2.433997    272.753575    186.092812   2270.499049     79.265038   \n",
      "min        0.000000      1.000000  57197.378446      0.000000      6.001704   \n",
      "25%        1.000000     25.000000  57275.173537      7.000000     10.510364   \n",
      "50%        4.000000    111.000000  57328.330289     13.000000     11.301913   \n",
      "75%        6.000000    295.000000  57372.219326    273.000000     12.641252   \n",
      "max        6.000000   2001.000000  57893.840891  10039.000000  20954.304688   \n",
      "\n",
      "          BinFactor        Events         DMmax         DMmin        DMmean  \\\n",
      "count  73282.000000  7.328200e+04  73282.000000  73282.000000  73282.000000   \n",
      "mean      14.171406  5.290837e+03   1843.879770    355.848537   1106.626399   \n",
      "std       20.233713  3.448143e+04   3329.930528   1195.291547   2135.608269   \n",
      "min        1.000000  1.000000e+00      3.000000      0.000000      3.000000   \n",
      "25%        2.000000  4.000000e+00     10.000000      5.000000      7.500000   \n",
      "50%        4.000000  3.400000e+01     27.000000      7.000000     16.500000   \n",
      "75%       16.000000  4.890000e+02   2024.000000     16.000000    947.812319   \n",
      "max       64.000000  2.135578e+06  57287.182376  10035.000000  10035.500000   \n",
      "\n",
      "           ...            SNRmean     SNRmedian        SNRstd        MJDmax  \\\n",
      "count      ...       73282.000000  73282.000000  64897.000000  73282.000000   \n",
      "mean       ...          10.825329     10.658387      0.743531  57392.275809   \n",
      "std        ...          46.109982     39.122834     26.804128    186.092812   \n",
      "min        ...           6.001704      6.001704      0.000054  57197.378488   \n",
      "25%        ...          10.251887     10.206805      0.230245  57275.173608   \n",
      "50%        ...          10.439661     10.365805      0.384718  57328.330356   \n",
      "75%        ...          10.741671     10.604892      0.660508  57372.219390   \n",
      "max        ...       12332.098730  10400.867188   6749.039746  57893.840925   \n",
      "\n",
      "             MJDmin        MJDstd       MJDmean     MJDmedian    Label  \\\n",
      "count  73282.000000  6.489700e+04  73282.000000  73282.000000  73282.0   \n",
      "mean   57392.275781  9.672567e-06  57392.275795  57392.275795     -1.0   \n",
      "std      186.092807  1.114003e-05    186.092810    186.092810      0.0   \n",
      "min    57197.378486  0.000000e+00  57197.378488  57197.378488     -1.0   \n",
      "25%    57275.173588  3.599307e-07  57275.173599  57275.173603     -1.0   \n",
      "50%    57328.330310  3.922326e-06  57328.330332  57328.330337     -1.0   \n",
      "75%    57372.219335  1.773132e-05  57372.219352  57372.219337     -1.0   \n",
      "max    57893.840925  6.888869e-05  57893.840925  57893.840925     -1.0   \n",
      "\n",
      "       predictLabel  \n",
      "count       73282.0  \n",
      "mean           -1.0  \n",
      "std             0.0  \n",
      "min            -1.0  \n",
      "25%            -1.0  \n",
      "50%            -1.0  \n",
      "75%            -1.0  \n",
      "max            -1.0  \n",
      "\n",
      "[8 rows x 22 columns]\n",
      "['datfile' 'Beam' 'TSID' 'Buffer' 'MJDstart' 'bestDM' 'bestSNR' 'BinFactor'\n",
      " 'Events' 'DMmax' 'DMmin' 'DMmean' 'DMmedian' 'DMstd' 'SNRmean' 'SNRmedian'\n",
      " 'SNRstd' 'MJDmax' 'MJDmin' 'MJDstd' 'MJDmean' 'MJDmedian' 'Label'\n",
      " 'predictLabel']\n"
     ]
    }
   ],
   "source": [
    "print df.describe()\n",
    "print df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Add additional buffer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found features in  /home/griffin/data/alfa/priorityModel/snr14_dm50/snr14_dm50.ak\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr14_dm50/snr14_dm50.am\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr14_dm50/snr14_dm50.ai\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr14_dm50/snr14_dm50.al\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr14_dm50/snr14_dm50.aa\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr14_dm50/snr14_dm50.aj\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr14_dm50/snr14_dm50.ad\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr14_dm50/snr14_dm50.ag\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr14_dm50/snr14_dm50.ab\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr14_dm50/snr14_dm50.af\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr14_dm50/snr14_dm50.ac\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr14_dm50/snr14_dm50.ah\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr14_dm50/snr14_dm50.ae\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr11-14_dm50/snr11-14_dm50.ad\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr11-14_dm50/snr11-14_dm50.aa\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr11-14_dm50/snr11-14_dm50.ac\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr11-14_dm50/snr11-14_dm50.ab\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr11-14_dm50/snr11-14_dm50.af\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr11-14_dm50/snr11-14_dm50.aj\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr11-14_dm50/snr11-14_dm50.ai\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr11-14_dm50/snr11-14_dm50.ae\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr11-14_dm50/snr11-14_dm50.al\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr11-14_dm50/snr11-14_dm50.ah\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr11-14_dm50/snr11-14_dm50.ak\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr11-14_dm50/snr11-14_dm50.ag\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr10-11_dm50/snr10-11_dm50.ac\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr10-11_dm50/snr10-11_dm50.ag\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr10-11_dm50/snr10-11_dm50.aa\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr10-11_dm50/snr10-11_dm50.ah\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr10-11_dm50/snr10-11_dm50.ae\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr10-11_dm50/snr10-11_dm50.af\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr10-11_dm50/snr10-11_dm50.ad\n",
      "Found features in  /home/griffin/data/alfa/priorityModel/snr10-11_dm50/snr10-11_dm50.ab\n"
     ]
    }
   ],
   "source": [
    "# metadata and features pickles\n",
    "baseDedispDirs = [BASE_DATA_PATH + 'snr14_dm50/',\n",
    "                  BASE_DATA_PATH + 'snr11-14_dm50/',\n",
    "                  BASE_DATA_PATH + 'snr10-11_dm50/']\n",
    "#baseDedispDirs = [BASE_DATA_PATH + 'test/']\n",
    "\n",
    "for dDir in baseDedispDirs:\n",
    "    for subDir in os.listdir(dDir):\n",
    "        if os.path.isdir(dDir + '/' + subDir):\n",
    "            metaPklFns = glob.glob(dDir + subDir + '/*.meta.pkl')\n",
    "            if len(metaPklFns) > 0:\n",
    "                print 'Found features in ', dDir + subDir\n",
    "                \n",
    "                for mIdx, metaPkl in enumerate(metaPklFns):\n",
    "                    \n",
    "                    # Event meta-data\n",
    "                    baseMetaFn = os.path.basename(metaPkl)\n",
    "                    bufID = int(baseMetaFn.split('.')[1].split('buffer')[-1])\n",
    "                    metaDict = pickle.load(open(metaPkl, 'rb'))\n",
    "                    idx = df.loc[(df['datfile']==metaDict['dat']) & (df['Buffer']==bufID)].index\n",
    "                    \n",
    "                    df.ix[idx, 'filterbank'] = metaDict['filterbank']\n",
    "                        \n",
    "                    # Percent of a time series which is 0\n",
    "                    df.ix[idx, 'pctZero'] = metaDict.get('pctZero', 0.)\n",
    "                    # take the 0-dm time series derivative, calculate the percent of time series with derivative=0\n",
    "                    df.ix[idx, 'pctZeroDeriv'] = metaDict.get('pctZeroDeriv', 0.)\n",
    "                    \n",
    "                    # Overflow counter\n",
    "                    # number of values which are above 1e20 threshold\n",
    "                    ofDict = metaDict.get('overflows', {'ncount': 0, 'pct': 0.})\n",
    "                    df.ix[idx, 'ofCount'] = ofDict['ncount']\n",
    "                    df.ix[idx, 'ofPct'] = ofDict['pct']\n",
    "                    \n",
    "                    # Longest continuous run of a constant in the dedispersed time series\n",
    "                    # tuple: (maxRun, maxVal, maxRun / float(arr.size))\n",
    "                    longestRun = metaDict.get('longestRun', (0, 0., 0.))\n",
    "                    df.ix[idx, 'longestRun0'] = longestRun[0]\n",
    "                    df.ix[idx, 'longestRun1'] = longestRun[1]\n",
    "                    df.ix[idx, 'longestRun2'] = longestRun[2]\n",
    "                    \n",
    "                    # Global statistics of the DM-0 time series\n",
    "                    globalTimeStats = metaDict.get('globalTimeStats', {'std': 0., 'max': 0., 'posCount': 0, \\\n",
    "                                                                       'min': 0., 'negPct': 0., 'median': 0.,\\\n",
    "                                                                       'meanMedianRatio': 0., 'posPct': 0.,\\\n",
    "                                                                       'negCount': 0, 'maxMinRatio': 0.,\\\n",
    "                                                                       'mean': 0. })\n",
    "                    \n",
    "                    df.ix[idx, 'globtsStatsStd'] = globalTimeStats['std']\n",
    "                    df.ix[idx, 'globtsStatsMax'] = globalTimeStats['max']\n",
    "                    df.ix[idx, 'globtsStatsPosCnt'] = globalTimeStats['posCount']\n",
    "                    df.ix[idx, 'globtsStatsMin'] = globalTimeStats['min']\n",
    "                    df.ix[idx, 'globtsStatsNegPct'] = globalTimeStats['negPct']\n",
    "                    df.ix[idx, 'globtsStatsMedian'] = globalTimeStats['median']\n",
    "                    df.ix[idx, 'globtsStatsRatio0'] = globalTimeStats['meanMedianRatio']\n",
    "                    df.ix[idx, 'globtsStatsPosPct'] = globalTimeStats['posPct']\n",
    "                    df.ix[idx, 'globtsStatsNegCnt'] = globalTimeStats['negCount']\n",
    "                    df.ix[idx, 'globtsStatsRatio1'] = globalTimeStats['maxMinRatio']\n",
    "                    df.ix[idx, 'globtsStatsMean'] = globalTimeStats['mean']\n",
    "                    \n",
    "                    # Global statistics of the best DM time series\n",
    "                    globalDedispTimeStats = metaDict.get('globalDedispTimeStats', {'std': 0., 'max': 0., \\\n",
    "                                                                       'posCount': 0,\n",
    "                                                                       'min': 0., 'negPct': 0., 'median': 0.,\\\n",
    "                                                                       'meanMedianRatio': 0., 'posPct': 0.,\\\n",
    "                                                                       'negCount': 0, 'maxMinRatio': 0.,\\\n",
    "                                                                       'mean': 0. })\n",
    "                    \n",
    "                    df.ix[idx, 'globDedisptsStatsStd'] = globalDedispTimeStats['std']\n",
    "                    df.ix[idx, 'globDedisptsStatsMax'] = globalDedispTimeStats['max']\n",
    "                    df.ix[idx, 'globDedisptsStatsPosCnt'] = globalDedispTimeStats['posCount']\n",
    "                    df.ix[idx, 'globDedisptsStatsMin'] = globalDedispTimeStats['min']\n",
    "                    df.ix[idx, 'globDedisptsStatsNegPct'] = globalDedispTimeStats['negPct']\n",
    "                    df.ix[idx, 'globDedisptsStatsMedian'] = globalDedispTimeStats['median']\n",
    "                    df.ix[idx, 'globDedisptsStatsRatio0'] = globalDedispTimeStats['meanMedianRatio']\n",
    "                    df.ix[idx, 'globDedisptsStatsPosPct'] = globalDedispTimeStats['posPct']\n",
    "                    df.ix[idx, 'globDedisptsStatsNegCnt'] = globalDedispTimeStats['negCount']\n",
    "                    df.ix[idx, 'globDedisptsStatsRatio1'] = globalDedispTimeStats['maxMinRatio']\n",
    "                    df.ix[idx, 'globDedisptsStatsMean'] = globalDedispTimeStats['mean']\n",
    "                    \n",
    "                    # Statistics of 16 segments of the DM-0 time series\n",
    "                    windZeros = np.zeros(16)\n",
    "                    windTime = metaDict.get('windTimeStats',{'std':windZeros, 'max':windZeros, \\\n",
    "                                                             'min':windZeros, 'snr':windZeros, \\\n",
    "                                                             'mean':windZeros})\n",
    "                    for i in range(16):\n",
    "                        df.ix[idx, 'windTimeStatsStd'+str(i)] = windTime['std'][i]\n",
    "                        df.ix[idx, 'windTimeStatsMax'+str(i)] = windTime['max'][i]\n",
    "                        df.ix[idx, 'windTimeStatsMin'+str(i)] = windTime['min'][i]\n",
    "                        df.ix[idx, 'windTimeStatsSnr'+str(i)] = windTime['snr'][i]\n",
    "                        df.ix[idx, 'windTimeStatsMean'+str(i)] = windTime['mean'][i]\n",
    "                        \n",
    "                    # Statistics of 16 segments of the best DM time series\n",
    "                    windDedispTime = metaDict.get('windDedispTimeStats',{'std':windZeros, 'max':windZeros,\\\n",
    "                                                                         'min':windZeros, 'snr':windZeros,\\\n",
    "                                                                         'mean':windZeros})\n",
    "                    for i in range(16):\n",
    "                        df.ix[idx, 'windDedispTimeStatsStd'+str(i)] = windDedispTime['std'][i]\n",
    "                        df.ix[idx, 'windDedispTimeStatsMax'+str(i)] = windDedispTime['max'][i]\n",
    "                        df.ix[idx, 'windDedispTimeStatsMin'+str(i)] = windDedispTime['min'][i]\n",
    "                        df.ix[idx, 'windDedispTimeStatsSnr'+str(i)] = windDedispTime['snr'][i]\n",
    "                        df.ix[idx, 'windDedispTimeStatsMean'+str(i)] = windDedispTime['mean'][i]\n",
    "                    \n",
    "                    # Statistics of the coarsely pixelized spectrogram\n",
    "                    pixelZeros = np.zeros((16, 4))\n",
    "                    pixels = metaDict.get('pixels',{'max':pixelZeros, 'min':pixelZeros, 'mean':pixelZeros})\n",
    "                    for i in range(16):\n",
    "                        for j in range(4):\n",
    "                            df.ix[idx, 'pixelMax_%i_%i'%(i,j)] = pixels['max'][i][j]\n",
    "                            df.ix[idx, 'pixelMin_%i_%i'%(i,j)] = pixels['max'][i][j]\n",
    "                            df.ix[idx, 'pixelMean_%i_%i'%(i,j)] = pixels['max'][i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60        0.000000\n",
      "62        0.000000\n",
      "63        0.000000\n",
      "73        0.000000\n",
      "74        0.000000\n",
      "76       17.259674\n",
      "77        0.000000\n",
      "137       0.000000\n",
      "183       0.000000\n",
      "184       0.000000\n",
      "185       0.000000\n",
      "190      18.284214\n",
      "191       0.000000\n",
      "195      26.616144\n",
      "196       0.000000\n",
      "197       0.000000\n",
      "198       0.000000\n",
      "200       0.000000\n",
      "201       0.000000\n",
      "202       0.000000\n",
      "203       0.000000\n",
      "206       0.000000\n",
      "207      11.540236\n",
      "209       0.000000\n",
      "210       0.000000\n",
      "212       0.000000\n",
      "213       0.000000\n",
      "214       0.000000\n",
      "215      11.769779\n",
      "217       0.000000\n",
      "           ...    \n",
      "66198    60.269836\n",
      "66199    35.591095\n",
      "66200    38.080162\n",
      "66201    39.586185\n",
      "66202    59.194279\n",
      "66203    40.457069\n",
      "66204    58.731380\n",
      "66205    46.999820\n",
      "66206    17.956202\n",
      "66207    41.805580\n",
      "66208     0.000000\n",
      "66209    47.248844\n",
      "66210    18.441801\n",
      "66211    20.029493\n",
      "66212    51.569515\n",
      "66213    45.532402\n",
      "66214    18.825869\n",
      "66215     7.698993\n",
      "66216     6.647788\n",
      "66217     0.000000\n",
      "66218    27.258652\n",
      "66219    26.679806\n",
      "66220    49.567158\n",
      "66221    22.849268\n",
      "66222    19.969896\n",
      "66223    22.177502\n",
      "66224    57.421879\n",
      "66225    18.806496\n",
      "66226    50.050800\n",
      "66227     0.000000\n",
      "Name: pixelMin_1_0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print df['pixelMin_1_0'].dropna()\n",
    "#print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr11-14_dm50.al.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr10-11_dm50.ah.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr14_dm50.ah.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr11-14_dm50.ac.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr10-11_dm50.ad.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr14_dm50.am.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr11-14_dm50.af.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr11-14_dm50.ag.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr11-14_dm50.aa.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr14_dm50.af.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr14_dm50.ai.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr14_dm50.aj.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr11-14_dm50.ai.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr10-11_dm50.ag.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr11-14_dm50.ae.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr11-14_dm50.ak.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr14_dm50.ae.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr10-11_dm50.ac.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr11-14_dm50.ab.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr11-14_dm50.ah.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr14_dm50.al.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr10-11_dm50.af.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr14_dm50.ab.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr14_dm50.ak.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr10-11_dm50.ab.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr11-14_dm50.aj.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr14_dm50.ag.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr14_dm50.ad.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr11-14_dm50.ad.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr10-11_dm50.ae.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr10-11_dm50.aa.pkl\n",
      "Reading labels from /home/griffin/data/alfa/priorityModel/allLabels/snr14_dm50.aa.pkl\n"
     ]
    }
   ],
   "source": [
    "# output of labelImg2.py\n",
    "labelPKlFiles = glob.glob(BASE_DATA_PATH + 'allLabels/*.pkl')\n",
    "\n",
    "# add assigned labels to main dataframe\n",
    "for lPkl in labelPKlFiles:\n",
    "    print 'Reading labels from', lPkl\n",
    "    labelDict = pickle.load(open(lPkl, 'rb'))\n",
    "    for key,val in labelDict.iteritems():\n",
    "        fbFN = key.split('buffer')[0] + 'fil'\n",
    "        bufID = int(key.split('.')[1].split('buffer')[-1])\n",
    "        df.loc[(df['filterbank']==fbFN) & (df['Buffer']==bufID), 'Label'] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    73282.000000\n",
      "mean         0.186676\n",
      "std          2.557381\n",
      "min         -1.000000\n",
      "25%         -1.000000\n",
      "50%         -1.000000\n",
      "75%         -1.000000\n",
      "max          9.000000\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print df['Label'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1    58212\n",
      " 6     4649\n",
      " 2     4159\n",
      " 3     1898\n",
      " 8     1594\n",
      " 7      863\n",
      " 9      685\n",
      " 5      617\n",
      " 4      448\n",
      " 1      151\n",
      " 0        6\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Save combined dataframe to file\n",
    "\n",
    "This would be a good point to split into a new notebook as the previous setups have been run to combine the various labels and features into a single dataframe. We will likely not need to re-run this code often, and as it takes a few minutes to run we can just save the final dataframe to file. Then use that dataframe as the starting point for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('featureDataframe.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
